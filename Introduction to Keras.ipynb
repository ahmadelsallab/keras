{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential vs. Functional, which to use and when?\n",
    "The Keras functional API is the way to go for defining complex models, such as multi-output models, directed acyclic graphs, or models with shared layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example cases of functional APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input and multi-output models\n",
    "\n",
    "https://keras.io/getting-started/functional-api-guide/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we insert the auxiliary loss, allowing the LSTM and Embedding layer to be trained smoothly even though the main loss will be much higher in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we feed into the model our auxiliary input data by concatenating it with the LSTM output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auxiliary_input = Input(shape=(5,), name='aux_input')\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines a model with two inputs and two outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model and assign a weight of 0.2 to the auxiliary loss. To specify different loss_weights or loss for each different output, you can use a list or a dictionary. Here we pass a single loss as the loss argument, so the same loss will be used on all outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the model by passing it lists of input arrays and target arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit([headline_data, additional_data], [labels, labels],\n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our inputs and outputs are named (we passed them a \"name\" argument), we could also have compiled the model via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
    "              loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
    "\n",
    "# And trained it via:\n",
    "model.fit({'main_input': headline_data, 'aux_input': additional_data},\n",
    "          {'main_output': labels, 'aux_output': labels},\n",
    "          epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Layers\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The concept of layer \"node\"\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception module --> Concatenate\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet--> layers.add\n",
    "https://keras.io/getting-started/functional-api-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared vision model\n",
    "This model reuses the same image-processing module on two inputs, to classify whether two MNIST digits are the same digit or different digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# First, define the vision modules\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "# Then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual question answering model\n",
    "This model can select the correct one-word answer when asked a natural-language question about a picture.\n",
    "\n",
    "It works by encoding the question into a vector, encoding the image into a vector, concatenating the two, and training on top a logistic regression over some vocabulary of potential answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# First, let's define a vision model using a Sequential model.\n",
    "# This model will encode an image into a vector.\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "# Now let's get a tensor with the output of our vision model:\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# Next, let's define a language model to encode the question into a vector.\n",
    "# Each question will be at most 100 word long,\n",
    "# and we will index words as integers from 1 to 9999.\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# Let's concatenate the question vector and the image vector:\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "# And let's train a logistic regression over 1000 words on top:\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "# This is our final model:\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "\n",
    "# The next stage would be training this model on actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video question answering model\n",
    "Now that we have trained our image QA model, we can quickly turn it into a video QA model. With appropriate training, you will be able to show it a short video (e.g. 100-frame human action) and ask a natural language question about the video (e.g. \"what sport is the boy playing?\" -> \"football\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "# This is our video encoded via the previously trained vision_model (weights are reused)\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "# This is a model-level representation of the question encoder, reusing the same weights as before:\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "# Let's use it to encode the question:\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "# And this is our video question answering model:\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I use Keras with datasets that don't fit in memory?\n",
    "1. Read from HDD yourself and use train_on_batch\n",
    "https://keras.io/models/sequential/\n",
    "2. Use fit_generator\n",
    "Alternatively, you can write a generator that yields batches of training data and use the method  model.fit_generator(data_generator, steps_per_epoch, epochs).\n",
    "CIFAR example:\n",
    "https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(path):\n",
    "    while True:\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                # create numpy arrays of input data\n",
    "                # and labels, from each line in the file\n",
    "                x1, x2, y = process_line(line)\n",
    "                yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
    "\n",
    "model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
    "                    steps_per_epoch=10000, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, a generator could be standard ImageDataGenerator from Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I interrupt training when the validation loss isn't decreasing anymore?\n",
    "You can use an EarlyStopping callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the validation split computed?\n",
    "If you set the validation_split argument in model.fit to e.g. 0.1, then the validation data used will be the last 10% of the data. If you set it to 0.25, it will be the last 25% of the data, etc. Note that the data isn't shuffled before extracting the validation split, so the validation is literally just the last x% of samples in the input you passed.\n",
    "\n",
    "The same validation set is used for all epochs (within a same call to fit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the data shuffled during training?\n",
    "Yes, if the shuffle argument in model.fit is set to True (which is the default), the training data will be randomly shuffled at each epoch.\n",
    "\n",
    "Validation data is never shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I record the training / validation loss / accuracy at each epoch?\n",
    "The model.fit method returns an History callback, which has a history attribute containing the lists of successive losses and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x, y, validation_split=0.2)\n",
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I \"freeze\" Keras layers?\n",
    "To \"freeze\" a layer means to exclude it from training, i.e. its weights will never be updated. This is useful in the context of fine-tuning a model, or using fixed embeddings for a text input.\n",
    "\n",
    "You can pass a trainable argument (boolean) to a layer constructor to set a layer to be non-trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frozen_layer = Dense(32, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can set the trainable property of a layer to True or False after instantiation. For this to take effect, you will need to call compile() on your model after modifying the trainable property. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(32,))\n",
    "layer = Dense(32)\n",
    "layer.trainable = False\n",
    "y = layer(x)\n",
    "\n",
    "frozen_model = Model(x, y)\n",
    "# in the model below, the weights of `layer` will not be updated during training\n",
    "frozen_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "layer.trainable = True\n",
    "trainable_model = Model(x, y)\n",
    "# with this model the weights of the layer will be updated during training\n",
    "# (which will also affect the above model since it uses the same layer instance)\n",
    "trainable_model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "frozen_model.fit(data, labels)  # this does NOT update the weights of `layer`\n",
    "trainable_model.fit(data, labels)  # this updates the weights of `layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I use stateful RNNs?\n",
    "Making a RNN stateful means that the states for the samples of each batch will be reused as initial states for the samples in the next batch.\n",
    "\n",
    "When using stateful RNNs, it is therefore assumed that:\n",
    "\n",
    "all batches have the same number of samples\n",
    "\n",
    "If x1 and x2 are successive batches of samples, then x2[i] is the follow-up sequence to x1[i], for every i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use statefulness in RNNs, you need to:\n",
    "\n",
    "- explicitly specify the batch size you are using, by passing a batch_size argument to the first layer in your model. E.g.  batch_size=32 for a 32-samples batch of sequences of 10 timesteps with 16 features per timestep.\n",
    "\n",
    "- set stateful=True in your RNN layer(s).\n",
    "\n",
    "- specify shuffle=False when calling fit()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reset the states accumulated:\n",
    "\n",
    "- use model.reset_states() to reset the states of all layers in the model\n",
    "- use layer.reset_states() to reset the states of a specific stateful RNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x  # this is our input data, of shape (32, 21, 16)\n",
    "# we will feed it to our model in sequences of length 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(10, 16), batch_size=32, stateful=True))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# we train the network to predict the 11th timestep given the first 10:\n",
    "model.train_on_batch(x[:, :10, :], np.reshape(x[:, 10, :], (32, 16)))\n",
    "\n",
    "# the state of the network has changed. We can feed the follow-up sequences:\n",
    "model.train_on_batch(x[:, 10:20, :], np.reshape(x[:, 20, :], (32, 16)))\n",
    "\n",
    "# let's reset the states of the LSTM layer:\n",
    "model.reset_states()\n",
    "\n",
    "# another way to do it in this case:\n",
    "model.layers[0].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the methods predict, fit, train_on_batch, predict_classes, etc. will all update the states of the stateful layers in a model. \n",
    "\n",
    "This allows you to do not only stateful training, but also stateful prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where is the Keras configuration file stored?\n",
    "The default directory where all Keras data is stored is: $HOME/.keras/\n",
    "    \n",
    "Note that Windows users should replace $HOME with %USERPROFILE%. In case Keras cannot create the above directory (e.g. due to permission issues), /tmp/.keras/ is used as a backup.\n",
    "\n",
    "The Keras configuration file is a JSON file stored at $HOME/.keras/keras.json. The default configuration file looks like this:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backend': 'tensorflow',\n",
       " 'epsilon': 1e-07,\n",
       " 'floatx': 'float32',\n",
       " 'image_data_format': 'channels_last'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "{\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains the following fields:\n",
    "\n",
    "The image data format to be used as default by image processing layers and utilities (either channels_last or  channels_first).\n",
    "\n",
    "- The epsilon numerical fuzz factor to be used to prevent division by zero in some operations.\n",
    " \n",
    "- The default float data type.\n",
    "\n",
    "- The default backend. See the backend documentation.\n",
    "\n",
    "\n",
    "Likewise, cached dataset files, such as those downloaded with get_file(), are stored by default in  $HOME/.keras/datasets/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How can I obtain reproducible results using Keras during development?\n",
    "During development of a model, sometimes it is useful to be able to obtain reproducible results from run to run in order to determine if a change in performance is due to an actual model or data modification, or merely a result of a new random sample. \n",
    "\n",
    "\n",
    "The below snippet of code provides an example of how to obtain reproducible results - this is geared towards a TensorFlow backend for a Python 3 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# The below is necessary in Python 3.2.3 onwards to\n",
    "# have reproducible behavior for certain hash-based operations.\n",
    "# See these references for further details:\n",
    "# https://docs.python.org/3.4/using/cmdline.html#envvar-PYTHONHASHSEED\n",
    "# https://github.com/keras-team/keras/issues/2280#issuecomment-306959926\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "\n",
    "rn.seed(12345)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Rest of code follows ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential in the constructor\n",
    "\n",
    "https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "The Sequential model is a linear stack of layers.\n",
    "\n",
    "You can create a Sequential model by passing a list of layer instances to the constructor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential as a stack (.add)\n",
    "You can also simply add layers via the .add() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras API conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape. There are several possible ways to do this:\n",
    "\n",
    "Pass an input_shape argument to the first layer. This is a shape tuple (a tuple of integers or None entries, where None indicates that any positive integer may be expected). In input_shape, the batch dimension is not included.\n",
    "\n",
    "\n",
    "Some 2D layers, such as Dense, support the specification of their input shape via the argument input_dim, and some 3D temporal layers support the arguments input_dim and input_length.\n",
    "\n",
    "\n",
    "If you ever need to specify a fixed batch size for your inputs (this is useful for stateful recurrent networks), you can pass a  batch_size argument to a layer. If you pass both batch_size=32 and input_shape=(6, 8) to a layer, it will then expect every batch of inputs to have the batch shape (32, 6, 8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, the following snippets are strictly equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input shape\n",
    "\n",
    "nD tensor with shape: (batch_size, ..., input_dim). The most common situation would be a 2D input with shape (batch_size, input_dim).\n",
    "\n",
    "#### Output shape\n",
    "\n",
    "nD tensor with shape: (batch_size, ..., units). For instance, for a 2D input with shape  (batch_size, input_dim), the output would have shape (batch_size, units)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# channels_first in conv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many layers, specially convolutional ones, like (Flatten, Conv2D,...etc), we find an arg \"data_format\": \n",
    "\n",
    "A string, one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs.\n",
    "\n",
    "The purpose of this argument is to preserve weight ordering when switching a model from one data format to another. channels_last corresponds to inputs with shape  (batch, ..., channels) while channels_first corresponds to inputs with shape (batch, channels, ...). \n",
    "\n",
    "It defaults to the image_data_format value found in your Keras config file at  ~/.keras/keras.json. If you never set it, then it will be \"channels_last\".\n",
    "\n",
    "When using the TF backend, channels_last (NHWC) is faster on CPU, while channels_first (NCHW) is faster for GPU.\n",
    "\n",
    "Quote from https://www.tensorflow.org/performance/performance_models:\n",
    "\"Most TensorFlow operations used by a CNN support both NHWC and NCHW data format. On GPU, NCHW is faster. But on CPU, NHWC is sometimes faster.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special layers\n",
    "\n",
    "An input to Keras layer (e.g. in Functional model) must be output of another keras layer. This is similar to tensors in tensorflow graph. The idea is to have one symbolic graph.\n",
    "\n",
    "For this reason, some simple matrix/tensor operations must be perfromed using special keras layers, like Lambda (slice), Cropping, Upsampling, ZeroPadding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to crop manual we get the error:\n",
    "    Output tensors to a Model must be Keras tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Output tensors to a Model must be Keras tensors. Found: Tensor(\"strided_slice:0\", shape=(?, 100), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b322f3a4336a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adadelta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m   1574\u001b[0m                 \u001b[0mcls_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1575\u001b[0m                 raise TypeError('Output tensors to a ' + cls_name + ' must be '\n\u001b[1;32m-> 1576\u001b[1;33m                                 'Keras tensors. Found: ' + str(x))\n\u001b[0m\u001b[0;32m   1577\u001b[0m         \u001b[1;31m# Build self.output_layers:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Output tensors to a Model must be Keras tensors. Found: Tensor(\"strided_slice:0\", shape=(?, 100), dtype=float32)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Cropping1D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "# Crop 10 from start and 10 from end\n",
    "out = inputs[10:90]\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "cropping1d_3 (Cropping1D)    (None, 80, 1)             0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Cropping1D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(100,1))\n",
    "# Crop 10 from start and 10 from end\n",
    "out = Cropping1D(cropping=(10,10))(inputs)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape\n",
    "Imagine the input is 1D of shape [100,], while the keras APIs expext [100,1].\n",
    "\n",
    "We have 2 solutions:\n",
    "\n",
    "1. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "cropping1d_4 (Cropping1D)    (None, 80, 1)             0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Cropping1D, Reshape\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "#import keras.backend as K\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "main_l = Reshape(target_shape=(100,1))(inputs)\n",
    "#main_l = K.expand_dims()\n",
    "# Crop 10 from start and 10 from end\n",
    "out = Cropping1D(cropping=(10,10))(main_l)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. expand_dims as in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do it with numpy we get error:\n",
    "\n",
    "    Layer cropping1d_6 was called with an input that isn't a symbolic tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer cropping1d_6 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([<tf.Tensor 'input_14:0' shape=(?, 100) dtype=float32>], dtype=object)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    402\u001b[0m                           tf.SparseTensor)):\n\u001b[1;32m--> 403\u001b[1;33m         raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n\u001b[0m\u001b[0;32m    404\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e29565cb84e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#main_l = K.expand_dims()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Crop 10 from start and 10 from end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCropping1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer cropping1d_6 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([<tf.Tensor 'input_14:0' shape=(?, 100) dtype=float32>], dtype=object)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Cropping1D, Reshape\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "#main_l = Reshape(target_shape=(100,1))(inputs)\n",
    "main_l = np.expand_dims(inputs, axis=-1)\n",
    "\n",
    "# Crop 10 from start and 10 from end\n",
    "out = Cropping1D(cropping=(10,10))(main_l)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keras backend expand_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But Keras backend does not provide Keras layer output!\n",
    "\n",
    "It's not enough to have a symbolic tensor to build Keras model, but it must be also an output of Keras layer.\n",
    "\n",
    "The symptom of that is that we get the following error:\n",
    "\n",
    "'Tensor' object has no attribute '_keras_history'\n",
    "\n",
    "We can print _keras_history after each step to see the layer name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<keras.engine.topology.InputLayer object at 0x0000024B4F889E80>, 0, 0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_keras_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-a8efe7367e76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#main_l = Reshape(target_shape=(100,1))(inputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmain_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 'Tensor' object has no attribute '_keras_history'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_keras_history'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Cropping1D, Reshape\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "inputs = Input(shape=(100,))\n",
    "print(inputs._keras_history)\n",
    "#main_l = Reshape(target_shape=(100,1))(inputs)\n",
    "main_l = K.expand_dims(inputs, axis=-1)\n",
    "print(main_l._keras_history)# 'Tensor' object has no attribute '_keras_history'\n",
    "\n",
    "\n",
    "# Crop 10 from start and 10 from end\n",
    "out = Cropping1D(cropping=(10,10))(main_l)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So the best option is Reshape layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# But what is the use of Keras backend?\n",
    "\n",
    "Keras is a model-level library, providing high-level building blocks for developing deep learning models. \n",
    "\n",
    "It does not handle itself low-level operations such as tensor products, convolutions and so on.\n",
    "\n",
    "Instead, it relies on a specialized, well-optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. \n",
    "\n",
    "Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations in backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing Tensors with Random Numbers\n",
    "b = K.random_uniform_variable(shape=(3, 4), low=0, high=1) # Uniform distribution\n",
    "c = K.random_normal_variable(shape=(3, 4), mean=0, scale=1) # Gaussian distribution\n",
    "d = K.random_normal_variable(shape=(3, 4), mean=0, scale=1)\n",
    "\n",
    "# Tensor Arithmetic\n",
    "a = b + c * K.abs(d)\n",
    "c = K.dot(a, K.transpose(b))\n",
    "a = K.sum(b, axis=1)\n",
    "a = K.softmax(b)\n",
    "a = K.concatenate([b, c], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But those tensors cannot be used in Functional model, as tehy do not implement Layer of keras, adn hence do not have _keras_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# now: model.output_shape == (None, 64, 10)\n",
    "# note: `None` is the batch dimension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda\n",
    "Can be used to apply lamda expression on the layer and produce Keras layer as well.\n",
    "Useful in input slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "input_l = Input(shape=[5,1])\n",
    "print(input_l._keras_history)\n",
    "print(input_l.shape)\n",
    "\n",
    "#category0 = Input(shape=[1])\n",
    "#category0 = input_l[:,0]# --> This is invalid since category0 is not an output of keras layer anymore, so it doesnt have any of the keras layer attribs like _leras_history\n",
    "#print(category0.shape) #--> (?,) while it should be (?,1) so that Embedding layer can be indexed\n",
    "category0 = Lambda(lambda x: x[:,0])(input_l)\n",
    "print(category0._keras_history)\n",
    "print(category0.shape)\n",
    "category1 = Lambda(lambda x: x[:,1])(input_l)\n",
    "print(category1.shape)\n",
    "category2 = Lambda(lambda x: x[:,2])(input_l)\n",
    "category3 = Lambda(lambda x: x[:,3])(input_l)\n",
    "category4 = Lambda(lambda x: x[:,4])(input_l)\n",
    "\n",
    "#Embeddings layers\n",
    "max_feature_nominal_value = 3\n",
    "embedding_vector_size = 50\n",
    "emb_category0 = Embedding(max_feature_nominal_value, embedding_vector_size)(category0)\n",
    "print(emb_category0.shape)\n",
    "emb_category1 = Embedding(max_feature_nominal_value, embedding_vector_size)(category1)\n",
    "emb_category2 = Embedding(max_feature_nominal_value, embedding_vector_size)(category2)\n",
    "emb_category3 = Embedding(max_feature_nominal_value, embedding_vector_size)(category3)\n",
    "emb_category4 = Embedding(max_feature_nominal_value, embedding_vector_size)(category4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "keras.layers.Masking(mask_value=0.0)\n",
    "\n",
    "Useful to skip some sequences from time steps when the value = mask_value.\n",
    "Skip means not to run feed fwd at all, not feeding 0's. \n",
    "\n",
    "Example\n",
    "\n",
    "Consider a Numpy data array x of shape (samples, timesteps, features), to be fed to an LSTM layer. You want to mask timestep #3 and #5 because you lack data for these timesteps. You can:\n",
    "\n",
    "- set x[:, 3, :] = 0. and x[:, 5, :] = 0.\n",
    "- insert a Masking layer with mask_value=0. before the LSTM layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(timesteps, features)))\n",
    "model.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroPadding\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convlution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D\n",
    "1D conv also called temporal convolution. \n",
    "\n",
    "## Input shape\n",
    "\n",
    "3D tensor with shape: (batch_size, steps, input_dim) --> e.g. (batch_sz, num_words_per_sent, emb_sz)\n",
    "\n",
    "## Output shape\n",
    "\n",
    "3D tensor with shape: (batch_size, new_steps, filters).\n",
    "\n",
    "steps value might have changed due to padding or strides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1D vs. Conv2D \n",
    "\n",
    "Conv2D is spatial while Conv1D is temporal conv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input shape\n",
    "\n",
    "4D tensor with shape: (samples, channels, rows, cols) if data_format is \"channels_first\" or 4D tensor with shape: (samples, rows, cols, channels) if data_format is \"channels_last\".\n",
    "\n",
    "## Output shape\n",
    "\n",
    "4D tensor with shape: (samples, filters, new_rows, new_cols) if data_format is \"channels_first\" or 4D tensor with shape: (samples, new_rows, new_cols, filters) if data_format is \"channels_last\". rows and  cols values might have changed due to padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separable convolution\n",
    "https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeparableConv1D\n",
    "## SeparableConv2D\n",
    "\n",
    "Separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The  depth_multiplier argument controls how many output channels are generated per input channel in the depthwise step.\n",
    "\n",
    "### Size reduction\n",
    "For NC_inHW and C_out (where C_in is the #of input channels and C_out is the #of output channels:\n",
    "\n",
    "Conv2D params = C_inxC_outxHxW\n",
    "\n",
    "SeparableConv2D params = C_inxHxW + C_outx1x1 (1x1Conv)= C_inxHxW + C_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2DTranspose (NOT Deconvolution)\n",
    "https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d\n",
    "\n",
    "A transposed convolution is somewhat similar because it produces the same spatial resolution a hypothetical deconvolutional layer would. However, the actual mathematical operation thats being performed on the values is different. A transposed convolutional layer carries out a regular convolution but reverts its spatial transformation.\n",
    "\n",
    "Example:\n",
    "An image of 5x5 is fed into a convolutional layer. The stride is set to 2, the padding is deactivated and the kernel is 3x3. This results in a 2x2 image.\n",
    "\n",
    "If we wanted to reverse this process, wed need the inverse mathematical operation so that 9 values are generated from each pixel we input. Afterward, we traverse the output image with a stride of 2. This would be a deconvolution.\n",
    "\n",
    "A transposed convolution does not do that. The only thing in common is it guarantees that the output will be a 5x5 image as well, while still performing a normal convolution operation. To achieve this, we need to perform some fancy padding on the input.\n",
    "As you can imagine now, this step will not reverse the process from above. At least not concerning the numeric values.\n",
    "It merely reconstructs the spatial resolution from before and performs a convolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure Deconv operation\n",
    "https://distill.pub/2016/deconv-checkerboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 64, 64, 1)     28          input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 64, 64, 1)     0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 64, 64, 64)    640         activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 64, 64, 64)    0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 64, 64, 64)    36928       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 64, 64, 64)    0           conv2d_transpose_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 64, 64, 65)    0           activation_14[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTransp (None, 64, 64, 1)     586         concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 64, 64, 1)     0           conv2d_transpose_7[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 38,182\n",
      "Trainable params: 38,182\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Activation, concatenate\n",
    "#from keras.activations import Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "conv_1 = Conv2D(1, (3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "act_1 = Activation('relu')(conv_1)\n",
    "\n",
    "\n",
    "conv_2 = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(act_1)\n",
    "act_2 = Activation('relu')(conv_2)\n",
    "\n",
    "deconv_1 = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same')(act_2)\n",
    "act_3 = Activation('relu')(deconv_1)\n",
    "\n",
    "merge_1 = concatenate([act_3, act_1], axis=3)\n",
    "\n",
    "deconv_2 = Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same')(merge_1)\n",
    "act_4 = Activation('relu')(deconv_2)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[act_4])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential vs. Functional model revisited\n",
    "\n",
    "Two differences we can see:\n",
    "    1. model.output_shape at each step\n",
    "    2. special layers like concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's debug the output shape. For this we need to switch to sequential model, o.w. we need to build model at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 1)\n",
      "(None, 64, 64, 64)\n",
      "(None, 64, 64, 64)\n",
      "(None, 64, 64, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 1)         28        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 64, 64, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 64, 64, 1)         0         \n",
      "=================================================================\n",
      "Total params: 38,173\n",
      "Trainable params: 38,173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Activation, concatenate\n",
    "#from keras.activations import Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "#inputs = Input(shape=(64, 64, 3))\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), strides=(1, 1), padding='same', input_shape=(64, 64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "print(model.output_shape)\n",
    "model.add(Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "# merge_1 = concatenate([act_3, act_1], axis=3) Now we cannot do it in sequential\n",
    "\n",
    "model.add(Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeparableConv revisited\n",
    "See the effect of params reduction in case of SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7f13fdb7b9b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mconv_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeparableConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mact_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdeconv_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Activation, concatenate, SeparableConv2D\n",
    "#from keras.activations import Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(64, 64, 3))\n",
    "\n",
    "conv_1 = SeparableConv2D(1, (3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "act_1 = Activation('relu')(conv_1)\n",
    "print(model.output_shape)\n",
    "\n",
    "conv_2 = SeparableConv2D(64, (3, 3), strides=(1, 1), padding='same')(act_1)\n",
    "act_2 = Activation('relu')(conv_2)\n",
    "print(model.output_shape)\n",
    "\n",
    "deconv_1 = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same')(act_2)\n",
    "act_3 = Activation('relu')(deconv_1)\n",
    "\n",
    "merge_1 = concatenate([act_3, act_1], axis=3)\n",
    "\n",
    "deconv_2 = Conv2DTranspose(1, (3, 3), strides=(1, 1), padding='same')(merge_1)\n",
    "act_4 = Activation('relu')(deconv_2)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[act_4])\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=categorical_crossentropy, metrics=[categorical_crossentropy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling2D vs Conv2DTranspose\n",
    "Upsampling2D: Repeats the rows and columns of the data by size[0] and size[1] respectively.\n",
    "\n",
    "Conv2DTranspose: Mulitplies a kernel by a padded input version to achieve a desired output shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxPooling vs. GlobalMaxPooling and AveragePooling vs. GlobalAveragePooling\n",
    "\n",
    "For example, if the input of the max pooling layer is 0,1,2,2,5,1,2, global max pooling outputs 5, whereas ordinary max pooling layer with pool size equals to 3 outputs 2,2,5,5,5 (assuming stride=1).\n",
    "\n",
    "That's why MaxPooling1D takes a pool_length argument, whereas GlobalMaxPooling1D does not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally connected layers\n",
    "The LocallyConnected1D layer works similarly to the Conv1D layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n",
    "\n",
    "Higher number of params vs. much more model capacity (and risk of overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimization (compile)\n",
    "Before training a model, you need to configure the learning process, which is done via the compile method. It receives three arguments:\n",
    "\n",
    "An optimizer. This could be the string identifier of an existing optimizer (such as rmsprop or adagrad), or an instance of the  Optimizer class. See: optimizers.\n",
    "\n",
    "A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (such as categorical_crossentropy or mse), or it can be an objective function. See: losses.\n",
    "\n",
    "A list of metrics. For any classification problem you will want to set this to metrics=['accuracy']. A metric could be the string identifier of an existing metric or a custom metric function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a multi-class classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# For a mean squared error regression problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data and Training\n",
    "Keras models are trained on Numpy arrays of input data and labels. For training a model, you will typically use the  fit function. Read its documentation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For a single-input model with 10 classes (categorical classification):\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stateful LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stateful recurrent model is one for which the internal states (memories) obtained after processing a batch of samples are reused as initial states for the samples of the next batch. This allows to process longer sequences while keeping computational complexity manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that we have to provide the full batch_input_shape since the network is stateful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# Note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why all tensors must come from Keras layer?\n",
    "(Mercari, slicing Lamda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categrial input handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification targets handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras integration with tf (tf.contrib.keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras from TF (tf.keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence handling with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable sequence length RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi stream architectures and input slicing (Lambda layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras pipeline (from_directory and from_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation through Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models and Transfer learning (Dogs vs. Cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Adding custom layers to Keras"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
